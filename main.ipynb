{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1c519b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03b45c",
   "metadata": {},
   "source": [
    "#### paste following lines into anaconda prompt (as admin) and press enter: \n",
    "#### conda install -c huggingface -c conda-forge datasets\n",
    "#### conda install -c anaconda gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be193bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vince\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vince\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vince\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\vince\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re, string, nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec, FastText\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a1ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data set: text & labels [World (0), Sports (1), Business (2), Sci/Tech (3)]\n",
    "dataset = load_dataset(\"ag_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127401ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "from pathlib import Path\n",
    "filepath = Path(r\"C:\\Users\\vince\\Desktop\\abcd\\out.csv\")  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "test_df.to_csv(filepath)\n",
    "\n",
    "# import os  \n",
    "# os.makedirs('folder/subfolder', exist_ok=True)  \n",
    "# df.to_csv('folder/subfolder/out.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235bdb01",
   "metadata": {},
   "source": [
    "# Train test split and class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# train test split\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "\n",
    "# checking class distribution\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "## train data\n",
    "plt.subplot(1,2,1)\n",
    "train_df_target = train_df['label']\n",
    "class_dist = pd.Series(train_df_target).value_counts()\n",
    "plt.title('train_df')\n",
    "plt.bar(class_dist.index, class_dist)\n",
    "plt.tight_layout()\n",
    "\n",
    "## test data\n",
    "plt.subplot(1,2,2)\n",
    "test_df_target = test_df['label']\n",
    "class_dist = pd.Series(test_df_target).value_counts()\n",
    "plt.title('test_df')\n",
    "plt.bar(class_dist.index, class_dist)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d721d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocessing(text):\n",
    "    \n",
    "    # convert to lowercase and remove spaces at beginning and ending\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)\n",
    "    \n",
    "    # remove html code\n",
    "    text= re.sub('<.*?>', '', text) \n",
    "    \n",
    "    # remove special characters\n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    \n",
    "    # remove digits\n",
    "    text = re.sub(r'\\d',' ',text)\n",
    "    \n",
    "    # replace multiple whitespaces with one\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    # stop word removal\n",
    "    clean_text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    # tonkenize & lemmatize\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(clean_text)) # -> list of tuples (word, pos_tag) [('computer', 'NN'), ('word', 'tag')]\n",
    "    lem_text = ' '.join([wnl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for tag in word_pos_tags])\n",
    "\n",
    "    return lem_text\n",
    "\n",
    " \n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        # default pos\n",
    "        return wordnet.NOUN\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute preprocessing for training set\n",
    "train_df['text'] = train_df['text'].apply(lambda x: preprocessing(x))\n",
    "train_df.to_csv('training_data.csv', sep=';', encoding='utf-8', index=False)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf6fb62",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b24275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in preprocessed training data if necessary\n",
    "train_df = pd.read_csv('preprocessed_training_data.csv', sep=';', encoding='utf-8')\n",
    "#for quick-testing with small memory\n",
    "train_df = train_df.sample(frac=0.01, random_state=42)\n",
    "# for word embedding models\n",
    "train_tokens = [word_tokenize(text) for text in train_df['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9387d88e",
   "metadata": {},
   "source": [
    "### Count vectors and Tf-idf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb9c4bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "count_vectorizer = CountVectorizer()\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(train_df['text'])\n",
    "count_vectors = count_vectorizer.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc87a9f",
   "metadata": {},
   "source": [
    "### Word2Vec SkipGram & CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ae686c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_cbow = Word2Vec(train_tokens, min_count=2, window=5)\n",
    "w2v_skipg = Word2Vec(train_tokens, min_count=2, window=5, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "431909b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns mean w2v vector for list of specified words\n",
    "def get_embedding(model, text):\n",
    "    existing_words = [word for word in text if word in model.wv.vocab]\n",
    "    if existing_words:\n",
    "        embedding = np.zeros((len(existing_words), model.vector_size), dtype=np.float32)\n",
    "        for i, w in enumerate(existing_words):\n",
    "                embedding[i] = model.wv[w]\n",
    "        return np.mean(embedding, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "783182c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get mean vector for each article description for both models\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m embeddings_w2v_cbow \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_embedding(w2v_cbow, text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m train_tokens])\n\u001b[0;32m      3\u001b[0m embeddings_w2v_skipg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_embedding(w2v_skipg, text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m train_tokens])\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get mean vector for each article description for both models\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m embeddings_w2v_cbow \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw2v_cbow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m train_tokens])\n\u001b[0;32m      3\u001b[0m embeddings_w2v_skipg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_embedding(w2v_skipg, text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m train_tokens])\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36mget_embedding\u001b[1;34m(model, text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embedding\u001b[39m(model, text):\n\u001b[1;32m----> 3\u001b[0m     existing_words \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m text \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mvocab]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m existing_words:\n\u001b[0;32m      5\u001b[0m         embedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(existing_words), model\u001b[38;5;241m.\u001b[39mvector_size), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embedding\u001b[39m(model, text):\n\u001b[1;32m----> 3\u001b[0m     existing_words \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m text \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m existing_words:\n\u001b[0;32m      5\u001b[0m         embedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(existing_words), model\u001b[38;5;241m.\u001b[39mvector_size), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\gensim\\models\\keyedvectors.py:735\u001b[0m, in \u001b[0;36mKeyedVectors.vocab\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvocab\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 735\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    736\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe vocab attribute was removed from KeyedVector in Gensim 4.0.0.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse KeyedVector\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms .key_to_index dict, .index_to_key list, and methods \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    738\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    740\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ]
    }
   ],
   "source": [
    "# get mean vector for each article description for both models\n",
    "embeddings_w2v_cbow = np.array([get_embedding(w2v_cbow, text) for text in train_tokens])\n",
    "embeddings_w2v_skipg = np.array([get_embedding(w2v_skipg, text) for text in train_tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20988705",
   "metadata": {},
   "source": [
    "### fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02f27af6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Either one of corpus_file or corpus_iterable value must be provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m fasttext \u001b[38;5;241m=\u001b[39m FastText(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m fasttext\u001b[38;5;241m.\u001b[39mtrain(sentences\u001b[38;5;241m=\u001b[39mtrain_tokens, total_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_tokens), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\gensim\\models\\word2vec.py:487\u001b[0m, in \u001b[0;36mWord2Vec.build_vocab\u001b[1;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_vocab\u001b[39m(\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28mself\u001b[39m, corpus_iterable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, corpus_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, progress_per\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m,\n\u001b[0;32m    448\u001b[0m         keep_raw_vocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, trim_rule\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    449\u001b[0m     ):\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;124;03m\"\"\"Build vocabulary from a sequence of sentences (can be a once-only generator stream).\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_corpus_sanity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m     total_words, corpus_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_vocab(\n\u001b[0;32m    489\u001b[0m         corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, progress_per\u001b[38;5;241m=\u001b[39mprogress_per, trim_rule\u001b[38;5;241m=\u001b[39mtrim_rule)\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_count \u001b[38;5;241m=\u001b[39m corpus_count\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\gensim\\models\\word2vec.py:1494\u001b[0m, in \u001b[0;36mWord2Vec._check_corpus_sanity\u001b[1;34m(self, corpus_iterable, corpus_file, passes)\u001b[0m\n\u001b[0;32m   1492\u001b[0m \u001b[38;5;124;03m\"\"\"Checks whether the corpus parameters make sense.\"\"\"\u001b[39;00m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither one of corpus_file or corpus_iterable value must be provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1496\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoth corpus_file and corpus_iterable must not be provided at the same time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Either one of corpus_file or corpus_iterable value must be provided"
     ]
    }
   ],
   "source": [
    "fasttext = FastText(window=5, min_count=2)\n",
    "fasttext.build_vocab(sentences=train_tokens)\n",
    "fasttext.train(sentences=train_tokens, total_examples=len(train_tokens), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1714253",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_fasttext = np.array([get_embedding(fasttext, text) for text in train_tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48028ba",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20533a2b",
   "metadata": {},
   "source": [
    "### Embeddings Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49f5b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#TODO: add the other matrices, when done\n",
    "embeddings = {\n",
    "    'tfidf_vectors': tfidf_vectors,\n",
    "    'count_vectors': count_vectors\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f276fe",
   "metadata": {},
   "source": [
    "### Hyperparameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "44509dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def KNeighbors_hyperParameterTune(matrix):\n",
    "    \n",
    "    knn_estimator = KNeighborsClassifier()\n",
    "    \n",
    "    decisionTree_parameters = {\n",
    "    'n_neighbors': range(2, 9)\n",
    "    }\n",
    "    \n",
    "    # specify the cross validation\n",
    "    stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    # create the grid search instance\n",
    "    grid_search_estimator = GridSearchCV(knn_estimator, decisionTree_parameters, scoring='accuracy', cv=stratified_10_fold_cv, return_train_score=False)\n",
    "    \n",
    "    # run the grid search\n",
    "    grid_search_estimator.fit(matrix.toarray(), train_df['label'])\n",
    "    \n",
    "    # print the results of all hyper-parameter combinations\n",
    "    results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "    display(results)\n",
    "    \n",
    "    # print the best parameter setting\n",
    "    print(\"KNeigborsClassifier: \" + key)\n",
    "    print(\"best score is {} with params {}\".format(grid_search_estimator.best_score_, grid_search_estimator.best_params_))\n",
    "    \n",
    "    return grid_search_estimator.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7cfdf9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033577</td>\n",
       "      <td>0.008574</td>\n",
       "      <td>0.050535</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 2}</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>0.026926</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032132</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.051711</td>\n",
       "      <td>0.010885</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.759167</td>\n",
       "      <td>0.017260</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032814</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.051563</td>\n",
       "      <td>0.010003</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.767500</td>\n",
       "      <td>0.034044</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031401</td>\n",
       "      <td>0.007004</td>\n",
       "      <td>0.049461</td>\n",
       "      <td>0.009694</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.784167</td>\n",
       "      <td>0.034651</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.048439</td>\n",
       "      <td>0.008410</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_neighbors': 6}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.780833</td>\n",
       "      <td>0.035949</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.029435</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.051205</td>\n",
       "      <td>0.015122</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.792500</td>\n",
       "      <td>0.030150</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.028128</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.053478</td>\n",
       "      <td>0.009867</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_neighbors': 8}</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.798333</td>\n",
       "      <td>0.028577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.033577      0.008574         0.050535        0.008889   \n",
       "1       0.032132      0.003950         0.051711        0.010885   \n",
       "2       0.032814      0.004681         0.051563        0.010003   \n",
       "3       0.031401      0.007004         0.049461        0.009694   \n",
       "4       0.028126      0.006247         0.048439        0.008410   \n",
       "5       0.029435      0.008400         0.051205        0.015122   \n",
       "6       0.028128      0.006249         0.053478        0.009867   \n",
       "\n",
       "  param_n_neighbors              params  split0_test_score  split1_test_score  \\\n",
       "0                 2  {'n_neighbors': 2}           0.733333           0.725000   \n",
       "1                 3  {'n_neighbors': 3}           0.766667           0.775000   \n",
       "2                 4  {'n_neighbors': 4}           0.808333           0.725000   \n",
       "3                 5  {'n_neighbors': 5}           0.791667           0.750000   \n",
       "4                 6  {'n_neighbors': 6}           0.791667           0.791667   \n",
       "5                 7  {'n_neighbors': 7}           0.808333           0.783333   \n",
       "6                 8  {'n_neighbors': 8}           0.808333           0.766667   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0           0.691667           0.691667           0.733333           0.700000   \n",
       "1           0.750000           0.766667           0.766667           0.725000   \n",
       "2           0.741667           0.808333           0.791667           0.725000   \n",
       "3           0.716667           0.825000           0.800000           0.741667   \n",
       "4           0.716667           0.791667           0.808333           0.766667   \n",
       "5           0.750000           0.800000           0.800000           0.758333   \n",
       "6           0.791667           0.816667           0.808333           0.783333   \n",
       "\n",
       "   split6_test_score  split7_test_score  split8_test_score  split9_test_score  \\\n",
       "0           0.741667           0.658333           0.708333           0.750000   \n",
       "1           0.758333           0.733333           0.766667           0.783333   \n",
       "2           0.766667           0.741667           0.750000           0.816667   \n",
       "3           0.783333           0.808333           0.800000           0.825000   \n",
       "4           0.750000           0.758333           0.775000           0.858333   \n",
       "5           0.783333           0.783333           0.791667           0.866667   \n",
       "6           0.791667           0.791667           0.758333           0.866667   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.713333        0.026926                7  \n",
       "1         0.759167        0.017260                6  \n",
       "2         0.767500        0.034044                5  \n",
       "3         0.784167        0.034651                3  \n",
       "4         0.780833        0.035949                4  \n",
       "5         0.792500        0.030150                2  \n",
       "6         0.798333        0.028577                1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeigborsClassifier: tfidf_vectors\n",
      "best score is 0.7983333333333335 with params {'n_neighbors': 8}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023821</td>\n",
       "      <td>0.008255</td>\n",
       "      <td>0.074302</td>\n",
       "      <td>0.009827</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 2}</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.376667</td>\n",
       "      <td>0.021344</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.073446</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.308333</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.072342</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015628</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.072847</td>\n",
       "      <td>0.011317</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.308333</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.037231</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022567</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>0.084440</td>\n",
       "      <td>0.011462</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.322500</td>\n",
       "      <td>0.077643</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023582</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.080065</td>\n",
       "      <td>0.009572</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_neighbors': 6}</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.094883</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.021858</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.083294</td>\n",
       "      <td>0.007701</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.308333</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.077010</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.022247</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.076744</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_neighbors': 8}</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.400833</td>\n",
       "      <td>0.053677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.023821      0.008255         0.074302        0.009827   \n",
       "1       0.015625      0.000024         0.073446        0.012217   \n",
       "2       0.015628      0.000005         0.072847        0.011317   \n",
       "3       0.022567      0.007378         0.084440        0.011462   \n",
       "4       0.023582      0.006882         0.080065        0.009572   \n",
       "5       0.021858      0.005354         0.083294        0.007701   \n",
       "6       0.022247      0.007882         0.076744        0.005108   \n",
       "\n",
       "  param_n_neighbors              params  split0_test_score  split1_test_score  \\\n",
       "0                 2  {'n_neighbors': 2}           0.366667           0.375000   \n",
       "1                 3  {'n_neighbors': 3}           0.300000           0.266667   \n",
       "2                 4  {'n_neighbors': 4}           0.291667           0.250000   \n",
       "3                 5  {'n_neighbors': 5}           0.291667           0.250000   \n",
       "4                 6  {'n_neighbors': 6}           0.283333           0.250000   \n",
       "5                 7  {'n_neighbors': 7}           0.366667           0.275000   \n",
       "6                 8  {'n_neighbors': 8}           0.450000           0.316667   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0           0.383333           0.333333           0.358333           0.383333   \n",
       "1           0.291667           0.275000           0.333333           0.316667   \n",
       "2           0.316667           0.291667           0.308333           0.291667   \n",
       "3           0.300000           0.275000           0.291667           0.291667   \n",
       "4           0.283333           0.258333           0.275000           0.283333   \n",
       "5           0.325000           0.291667           0.308333           0.325000   \n",
       "6           0.366667           0.341667           0.366667           0.383333   \n",
       "\n",
       "   split6_test_score  split7_test_score  split8_test_score  split9_test_score  \\\n",
       "0           0.416667           0.375000           0.400000           0.375000   \n",
       "1           0.308333           0.341667           0.533333           0.300000   \n",
       "2           0.283333           0.350000           0.391667           0.291667   \n",
       "3           0.300000           0.483333           0.466667           0.275000   \n",
       "4           0.283333           0.516667           0.500000           0.266667   \n",
       "5           0.341667           0.500000           0.508333           0.341667   \n",
       "6           0.400000           0.466667           0.491667           0.425000   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.376667        0.021344                2  \n",
       "1         0.326667        0.072342                4  \n",
       "2         0.306667        0.037231                7  \n",
       "3         0.322500        0.077643                5  \n",
       "4         0.320000        0.094883                6  \n",
       "5         0.358333        0.077010                3  \n",
       "6         0.400833        0.053677                1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeigborsClassifier: count_vectors\n",
      "best score is 0.4008333333333334 with params {'n_neighbors': 8}\n",
      "\n",
      "The best performance is reached with the estimator KNeighborsClassifier and the embedding tfidf_vectors with an accuracy of 0.7983333333333335\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "for key in embeddings:\n",
    "    \n",
    "    score = KNeighbors_hyperParameterTune(embeddings[key])\n",
    "    \n",
    "    estimators = {\n",
    "        'KNeighborsClassifier': score\n",
    "    }\n",
    "    \n",
    "    best_estimator_score = 0\n",
    "    for estimator in estimators:\n",
    "        estimator_score = estimators[estimator]\n",
    "        if estimator_score > best_estimator_score:\n",
    "            best_estimator_score = estimator_score\n",
    "            best_estimator = estimator\n",
    "    if score > best_score:\n",
    "        best_key = key\n",
    "        best_score = score\n",
    "        \n",
    "print(\"\\nThe best performance is reached with the estimator \" + best_estimator + \" and the embedding \" + best_key + \" with an accuracy of \" + str(best_score) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad6b198",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 30.9 GiB for an array with shape (80000, 51879) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# print(type(tfidf_vectors))\u001b[39;00m\n\u001b[0;32m      5\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m cross_val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMultinomialNB\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfidf_vectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(cross_val_acc\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:509\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    507\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 509\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 267\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:672\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    668\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcloned_parameters)\n\u001b[0;32m    670\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 672\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43m_safe_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    673\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, test, train)\n\u001b[0;32m    675\u001b[0m result \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:288\u001b[0m, in \u001b[0;36m_safe_split\u001b[1;34m(estimator, X, y, indices, train_indices)\u001b[0m\n\u001b[0;32m    286\u001b[0m         X_subset \u001b[38;5;241m=\u001b[39m X[np\u001b[38;5;241m.\u001b[39mix_(indices, train_indices)]\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m     X_subset \u001b[38;5;241m=\u001b[39m \u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m     y_subset \u001b[38;5;241m=\u001b[39m _safe_indexing(y, indices)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\utils\\__init__.py:378\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\utils\\__init__.py:202\u001b[0m, in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    201\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m array[:, key]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 30.9 GiB for an array with shape (80000, 51879) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# TODO: print(type(tfidf_vectors))\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_acc = cross_val_score(MultinomialNB(), tfidf_vectors.toarray(), train_df['label'], scoring='accuracy', cv=cv)\n",
    "print(cross_val_acc.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
