{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1c519b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03b45c",
   "metadata": {},
   "source": [
    "#### paste following lines into anaconda prompt (as admin) and press enter: \n",
    "#### conda install -c huggingface -c conda-forge datasets\n",
    "#### conda install -c anaconda gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be193bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re, string, nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235bdb01",
   "metadata": {},
   "source": [
    "# Train test split and class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d03c42a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vince\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vince\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vince\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\vince\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\vince\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099a4a622be94c928490daa60b09a612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# train-test split\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "del dataset\n",
    "\n",
    "def class_distribution():\n",
    "    \n",
    "    # checking class distribution\n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    ## train data\n",
    "    plt.subplot(1,2,1)\n",
    "    train_df_target = train_df['label']\n",
    "    class_dist = pd.Series(train_df_target).value_counts()\n",
    "    plt.title('train_df')\n",
    "    plt.bar(class_dist.index, class_dist)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ## test data\n",
    "    plt.subplot(1,2,2)\n",
    "    test_df_target = test_df['label']\n",
    "    class_dist = pd.Series(test_df_target).value_counts()\n",
    "    plt.title('test_df')\n",
    "    plt.bar(class_dist.index, class_dist)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def balanced_fractionize(df, frac):\n",
    "    \n",
    "    frac_df = df.sample(frac=frac, random_state=42)\n",
    "    frac_data, frac_target = frac_df['text'].values.reshape(-1, 1), frac_df['label'].values.reshape(-1, 1)\n",
    "    \n",
    "    sampler = RandomUnderSampler()\n",
    "    bal_frac_data, bal_frac_target = sampler.fit_resample(frac_data, frac_target)\n",
    "    \n",
    "    class_dist = pd.Series(bal_frac_target).value_counts()\n",
    "    plt.bar(class_dist.index, class_dist)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "    \n",
    "    return pd.DataFrame(bal_frac_data, columns = ['text']), pd.DataFrame(bal_frac_target, columns = ['label'])\n",
    "\n",
    "class_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d721d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocessing(text):\n",
    "    \n",
    "    # convert to lowercase and remove spaces at beginning and ending\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)\n",
    "    \n",
    "    # remove html code\n",
    "    text= re.sub('<.*?>', '', text) \n",
    "    \n",
    "    # remove special characters\n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    \n",
    "    # remove digits\n",
    "    text = re.sub(r'\\d',' ',text)\n",
    "    \n",
    "    # replace multiple whitespaces with one\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    # stop word removal\n",
    "    clean_text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    # tonkenize & lemmatize\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(clean_text)) # -> list of tuples (word, pos_tag) [('computer', 'NN'), ('word', 'tag')]\n",
    "    lem_text = ' '.join([wnl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for tag in word_pos_tags])\n",
    "\n",
    "    return lem_text\n",
    "\n",
    " \n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        # default pos\n",
    "        return wordnet.NOUN\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute preprocessing for training set\n",
    "train_df['text'] = train_df['text'].apply(lambda x: preprocessing(x))\n",
    "train_df.to_csv('training_data.csv', sep=';', encoding='utf-8', index=False)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf6fb62",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b24275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPrklEQVR4nO3df6xkdX3G8fcDrEGEBMhecEvRVUNQahDWhdJgLf4M0CjSaitpkBh1tZVEUv9wS43SP5rQRqE1bVQoRLRqi0V+1KIViEpMKnihq0AXi7WoyIa92tRdlUjBT/+Ys3qz3rv33L175tzl+34lN3N+zZzHr8OzM2fOnElVIUlqywFjB5AkTZ/lL0kNsvwlqUGWvyQ1yPKXpAYdNHaAPtauXVvr168fO4Yk7Vfuuuuu71fVzELr9ovyX79+PbOzs2PHkKT9SpJvL7bOwz6S1CDLX5IaZPlLUoMsf0lqkOUvSQ2y/CWpQZa/JDXI8pekBln+ktSg/eIbviuxfvO/jB1hVA9e+tsrur/j5/ithOO3cisdw8X4yl+SGmT5S1KDLH9JapDlL0kNGqz8kxyb5AtJtia5L8k7uuWXJPleki3d39lDZZAkLWzIs30eB95ZVXcnOQy4K8kt3brLq+p9A+5bkrQHg5V/VW0DtnXTO5NsBY4Zan+SpP6mcsw/yXrgZOCObtGFSb6e5OokRyxyn01JZpPMzs3NTSOmJDVj8PJPcihwHXBRVe0APgg8BziJyTuD9y90v6q6oqo2VtXGmZkFf4JSkrSXBi3/JGuYFP/Hq+rTAFX1SFU9UVU/A64ETh0ygyTplw15tk+Aq4CtVXXZvOXr5m12LnDvUBkkSQsb8myf04HzgXuSbOmWXQycl+QkoIAHgbcOmEGStIAhz/b5MpAFVt081D4lSf34DV9JapDlL0kNsvwlqUGWvyQ1yPKXpAZZ/pLUIMtfkhpk+UtSgyx/SWqQ5S9JDbL8JalBlr8kNcjyl6QGWf6S1CDLX5IaZPlLUoMsf0lqkOUvSQ2y/CWpQZa/JDXI8pekBln+ktQgy1+SGmT5S1KDLH9JapDlL0kNsvwlqUGWvyQ1yPKXpAZZ/pLUoMHKP8mxSb6QZGuS+5K8o1t+ZJJbkjzQ3R4xVAZJ0sKGfOX/OPDOqnoecBrw9iQnAJuB26rqOOC2bl6SNEWDlX9Vbauqu7vpncBW4BjgHOCabrNrgNcMlUGStLCpHPNPsh44GbgDOLqqtsHkHwjgqGlkkCT9wuDln+RQ4DrgoqrasYz7bUoym2R2bm5uuICS1KBByz/JGibF//Gq+nS3+JEk67r164DtC923qq6oqo1VtXFmZmbImJLUnCHP9glwFbC1qi6bt+om4IJu+gLgxqEySJIWdtCAj306cD5wT5It3bKLgUuBa5O8CfgO8LoBM0iSFjBY+VfVl4EssvplQ+1XkrQ0v+ErSQ2y/CWpQZa/JDXI8pekBln+ktQgy1+SGmT5S1KDLH9JapDlL0kNsvwlqUGWvyQ1yPKXpAZZ/pLUIMtfkhpk+UtSgyx/SWqQ5S9JDbL8JalBlr8kNcjyl6QGWf6S1CDLX5Ia1Kv8kzx/6CCSpOnp+8r/Q0nuTPJHSQ4fMpAkaXi9yr+qXgT8AXAsMJvkE0leMWgySdJgeh/zr6oHgHcD7wJ+C/hAkvuT/M5Q4SRJw+h7zP/EJJcDW4GXAq+qqud105cPmE+SNICDem73N8CVwMVV9eiuhVX1cJJ3D5JMkjSYvuV/NvBoVT0BkOQA4OCq+klVfWywdJKkQfQ95n8r8NR584d0yyRJ+6G+5X9wVf1o10w3fcgwkSRJQ+tb/j9OsmHXTJIXAo/uYXuSXJ1ke5J75y27JMn3kmzp/s7eu9iSpJXoe8z/IuBTSR7u5tcBv7/EfT7C5IPij+62/PKqel/fgJKkfa9X+VfVV5M8FzgeCHB/Vf3fEve5Pcn6lUeUJO1ry7mw2ynAicDJwHlJ3rCX+7wwyde7w0JHLLZRkk1JZpPMzs3N7eWuJEkL6fslr48B7wNexOQfgVOAjXuxvw8CzwFOArYB719sw6q6oqo2VtXGmZmZvdiVJGkxfY/5bwROqKpayc6q6pFd00muBD6zkseTJO2dvod97gWevtKdJVk3b/bc7nElSVPW95X/WuA/ktwJ/HTXwqp69WJ3SPJJ4AxgbZKHgPcCZyQ5CSjgQeCte5VakrQifcv/kuU+cFWdt8Diq5b7OJKkfa/vqZ5fSvJM4LiqujXJIcCBw0aTJA2l79k+bwH+Cfhwt+gY4IaBMkmSBtb3A9+3A6cDO+DnP+xy1FChJEnD6lv+P62qx3bNJDmIyYe2kqT9UN/y/1KSi4Gndr/d+yngn4eLJUkaUt/y3wzMAfcwOT3zZia/5ytJ2g/1PdvnZ0x+xvHKYeNIkqahV/kn+W8WOMZfVc/e54kkSYNbzrV9djkYeB1w5L6PI0mahl7H/KvqB/P+vldVfwW8dNhokqSh9D3ss2He7AFM3gkcNkgiSdLg+h72mX/d/ceZXJTt9/Z5GknSVPQ92+clQweRJE1P38M+f7yn9VV12b6JI0mahuWc7XMKcFM3/yrgduC7Q4SSJA1rOT/msqGqdgIkuQT4VFW9eahgkqTh9L28wzOAx+bNPwas3+dpJElT0feV/8eAO5Ncz+SbvucCHx0slSRpUH3P9vnzJJ8FfrNb9Maq+vfhYkmShtT3sA/AIcCOqvpr4KEkzxookyRpYH1/xvG9wLuAP+kWrQH+fqhQkqRh9X3lfy7wauDHAFX1MF7eQZL2W33L/7GqKrrLOid52nCRJElD61v+1yb5MHB4krcAt+IPu0jSfmvJs32SBPhH4LnADuB44D1VdcvA2SRJA1my/KuqktxQVS8ELHxJehLoe9jnK0lOGTSJJGlq+n7D9yXA25I8yOSMnzB5U3DiUMEkScPZY/kneUZVfQc4a0p5JElTsNQr/xuYXM3z20muq6rfnUImSdLAljrmn3nTzx4yiCRpepYq/1pkeklJrk6yPcm985YdmeSWJA90t0cs5zElSfvGUuX/giQ7kuwETuymdyTZmWTHEvf9CHDmbss2A7dV1XHAbd28JGnK9njMv6oO3NsHrqrbk6zfbfE5wBnd9DXAF5lcME6SNEXLuaTzvnB0VW0D6G6PWmzDJJuSzCaZnZubm1pASWrBtMu/t6q6oqo2VtXGmZmZseNI0pPKtMv/kSTrALrb7VPevySJ6Zf/TcAF3fQFwI1T3r8kiQHLP8kngX8Djk/yUJI3AZcCr0jyAPCKbl6SNGV9r+2zbFV13iKrXjbUPiVJ/azaD3wlScOx/CWpQZa/JDXI8pekBln+ktQgy1+SGmT5S1KDLH9JapDlL0kNsvwlqUGWvyQ1yPKXpAZZ/pLUIMtfkhpk+UtSgyx/SWqQ5S9JDbL8JalBlr8kNcjyl6QGWf6S1CDLX5IaZPlLUoMsf0lqkOUvSQ2y/CWpQZa/JDXI8pekBln+ktQgy1+SGmT5S1KDDhpjp0keBHYCTwCPV9XGMXJIUqtGKf/OS6rq+yPuX5Ka5WEfSWrQWOVfwOeT3JVk00IbJNmUZDbJ7Nzc3JTjSdKT21jlf3pVbQDOAt6e5MW7b1BVV1TVxqraODMzM/2EkvQkNkr5V9XD3e124Hrg1DFySFKrpl7+SZ6W5LBd08ArgXunnUOSWjbG2T5HA9cn2bX/T1TV50bIIUnNmnr5V9W3gBdMe7+SpF/wVE9JapDlL0kNsvwlqUGWvyQ1yPKXpAZZ/pLUIMtfkhpk+UtSgyx/SWqQ5S9JDbL8JalBlr8kNcjyl6QGWf6S1CDLX5IaZPlLUoMsf0lqkOUvSQ2y/CWpQZa/JDXI8pekBln+ktQgy1+SGmT5S1KDLH9JapDlL0kNsvwlqUGWvyQ1yPKXpAZZ/pLUIMtfkho0SvknOTPJN5J8M8nmMTJIUsumXv5JDgT+FjgLOAE4L8kJ084hSS0b45X/qcA3q+pbVfUY8A/AOSPkkKRmpaqmu8PktcCZVfXmbv584Ner6sLdttsEbOpmjwe+schDrgW+P1DcfcF8K2O+lTHfyqz2fLDnjM+sqpmFVhw0XJ5FZYFlv/QvUFVdAVyx5IMls1W1cV8EG4L5VsZ8K2O+lVnt+WDvM45x2Och4Nh5878KPDxCDklq1hjl/1XguCTPSvIU4PXATSPkkKRmTf2wT1U9nuRC4F+BA4Grq+q+FTzkkoeGRma+lTHfyphvZVZ7PtjLjFP/wFeSND6/4StJDbL8JalB+135JzkyyS1JHuhuj1hkuweT3JNkS5LZKeTa4yUrMvGBbv3Xk2wYOtMy852R5IfdeG1J8p4pZrs6yfYk9y6yfuyxWyrfaGPX7f/YJF9IsjXJfUnescA2o41hz3xjPv8OTnJnkq91+f5sgW3GHL8++ZY/flW1X/0Bfwls7qY3A3+xyHYPAmunlOlA4L+AZwNPAb4GnLDbNmcDn2XyPYfTgDumOGZ98p0BfGak/09fDGwA7l1k/Whj1zPfaGPX7X8dsKGbPgz4z1X2/OuTb8znX4BDu+k1wB3Aaato/PrkW/b47Xev/JlcCuKabvoa4DXjRfm5PpesOAf4aE18BTg8ybpVlG80VXU78D972GTMseuTb1RVta2q7u6mdwJbgWN222y0MeyZbzTdmPyom13T/e1+JsyY49cn37Ltj+V/dFVtg8mTCjhqke0K+HySu7pLRQzpGOC78+Yf4pef3H22GUrfff9G99bys0l+bTrRehlz7PpaFWOXZD1wMpNXh/OtijHcQz4YcQyTHJhkC7AduKWqVtX49cgHyxy/MS7vsKQktwJPX2DVny7jYU6vqoeTHAXckuT+7hXcEPpcsqLXZS0G0mffdzO5DsiPkpwN3AAcN3SwnsYcuz5WxdglORS4DrioqnbsvnqBu0x1DJfIN+oYVtUTwElJDgeuT/L8qpr/Gc+o49cj37LHb1W+8q+ql1fV8xf4uxF4ZNfbre52+yKP8XB3ux24nsmhj6H0uWTFmJe1WHLfVbVj11vLqroZWJNk7ZTyLWVVXxJkNYxdkjVMivXjVfXpBTYZdQyXyrcaxrDb9/8CXwTO3G3VqngOLpZvb8ZvVZb/Em4CLuimLwBu3H2DJE9LctiuaeCVwIJnauwjfS5ZcRPwhu6sgdOAH+46fDUFS+ZL8vQk6aZPZfLc+MGU8i1lzLFb0thj1+37KmBrVV22yGajjWGffGOOYZKZ7hU1SZ4KvBy4f7fNxhy/JfPtzfitysM+S7gUuDbJm4DvAK8DSPIrwN9V1dnA0UzeGsHkf+MnqupzQwWqRS5ZkeRt3foPATczOWPgm8BPgDcOlWcv870W+MMkjwOPAq+v7jSCoSX5JJOzFdYmeQh4L5MPtUYfu575Rhu7zunA+cA93XFhgIuBZ8zLOOYY9sk35hiuA67J5IemDgCurarPrJb/fnvmW/b4eXkHSWrQ/njYR5K0Qpa/JDXI8pekBln+ktQgy1+SGmT5S1KDLH9JatD/AzuBsFJXg8R8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in preprocessed training data if necessary\n",
    "train_df = pd.read_csv('preprocessed_training_data.csv', sep=';', encoding='utf-8')\n",
    "\n",
    "#fractionize and undersample data\n",
    "train_data, train_target = balanced_fractionize(train_df, 0.001)\n",
    "\n",
    "#Tokenize\n",
    "def get_train_tokens(df_data):\n",
    "    return [word_tokenize(text) for text in df_data['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9387d88e",
   "metadata": {},
   "source": [
    "### Count vectors and Tf-idf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb9c4bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfid_vectors(df_data):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    return tfidf_vectorizer.fit_transform(df_data['text']).toarray()\n",
    "\n",
    "def get_count_vectors(df_data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    return count_vectorizer.fit_transform(df_data['text']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc87a9f",
   "metadata": {},
   "source": [
    "### Word2Vec SkipGram & CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae686c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns mean w2v vector for list of specified words\n",
    "def get_embedding(model, text):\n",
    "    existing_words = [word for word in text if word in list(model.wv.index_to_key)]\n",
    "    if existing_words:\n",
    "        embedding = np.zeros((len(existing_words), model.vector_size), dtype=np.float32)\n",
    "        for i, w in enumerate(existing_words):\n",
    "                embedding[i] = model.wv[w]\n",
    "        return np.mean(embedding, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "    \n",
    "    \n",
    "def get_w2v_cbow_embeddings(tokens):\n",
    "    w2v_cbow = Word2Vec(tokens, min_count=2,vector_size=300, window=5)\n",
    "    # get mean vector for each article description for both models\n",
    "    return np.array([get_embedding(w2v_cbow, text) for text in tokens])\n",
    "\n",
    "def get_w2v_skipg_embeddings(tokens):\n",
    "    w2v_skipg = Word2Vec(tokens, min_count=2,vector_size=300, window=5, sg = 1)\n",
    "    # get mean vector for each article description for both models\n",
    "    return np.array([get_embedding(w2v_skipg, text) for text in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20988705",
   "metadata": {},
   "source": [
    "### fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02f27af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasttext_embeddings(tokens):\n",
    "    fasttext = FastText(vector_size=300, window=5, min_count=2)\n",
    "    fasttext.build_vocab(corpus_iterable=tokens)\n",
    "    fasttext.train(corpus_iterable=tokens, total_examples=len(tokens), epochs=10)\n",
    "    return np.array([get_embedding(fasttext, text) for text in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba9c7b4",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f02272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write content into file\n",
    "with open('corpus.txt', 'w') as f:\n",
    "    for text in train_data['text'].tolist():\n",
    "        f.write(text + '\\n')\n",
    "# train vectors with https://github.com/stanfordnlp/GloVe with standard parameters\n",
    "#Example vectors uploaded to Git were trained with 0.2 percent of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6ee6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_document_vector(text, vocab, vectors, vector_size):\n",
    "    existing_words = [word for word in text if word in vocab]\n",
    "    if existing_words:\n",
    "        embedding = np.zeros((len(existing_words), vector_size), dtype=np.float32)\n",
    "        for i, w in enumerate(existing_words):\n",
    "                embedding[i] = vectors[w]\n",
    "        return np.mean(embedding, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "\n",
    "# needs tokens from same fraction of training data as the GloVe embeddings were trained with\n",
    "def get_glove_embeddings(tokens):\n",
    "    vocab = []\n",
    "    vectors = {}\n",
    "    with open('vocab.txt') as f:\n",
    "        for ln in f:\n",
    "            words = ln.split()\n",
    "            vocab = vocab + words[:1]\n",
    "    with open('vectors.txt') as f:\n",
    "        for ln in f:\n",
    "            word = ln.split()[0]\n",
    "            vector = [float(number) for number in ln.split()[1:]]\n",
    "            vectors[word] = vector\n",
    "            \n",
    "    return np.array([get_glove_document_vector(text, vocab, vectors, len(vector)) for text in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad51cc90",
   "metadata": {},
   "source": [
    "# Vectorizer Names & Get_vectorMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd7094c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_names = [\"tfidf_vectors\", \"count_vectors\", \"w2v_cbow\", \"w2v_skipg\", \"fasttext\", \"GloVe\"]\n",
    "\n",
    "#returns vector-matrix with specified vectorizer on specified data\n",
    "def get_vectorMatrix(vectorizer_name, df_data):\n",
    "    for vectorizer_name in vectorizer_names:\n",
    "        if vectorizer_name == \"tfidf_vectors\":\n",
    "            return get_tfid_vectors(df_data)\n",
    "        elif vectorizer_name == \"count_vectors\":\n",
    "            return get_count_vectors(train_data)\n",
    "        elif vectorizer_name == \"w2v_cbow\":\n",
    "            train_tokens = get_train_tokens(train_data)\n",
    "            return get_w2v_cbow_embeddings(train_tokens)\n",
    "        elif vectorizer_name == \"w2v_skipg\":\n",
    "            train_tokens = get_train_tokens(train_data)\n",
    "            return get_w2v_skipg_embeddings(train_tokens)\n",
    "        elif vectorizer_name == \"fasttext\":\n",
    "            train_tokens = get_train_tokens(train_data)\n",
    "            return get_fasttext_embeddings(train_tokens)\n",
    "        elif vectorizer_name == \"GloVe\":\n",
    "            train_tokens = get_train_tokens(train_data)\n",
    "            return get_glove_embeddings(train_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48028ba",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389aca43",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab54ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "def param_search(vector_matrix, vector_matrix_name, estimator):\n",
    "    \n",
    "    estimator_name = estimator['name']\n",
    "    parameters = estimator['parameters']\n",
    "    estimator = estimator['estimator']\n",
    "    \n",
    "    # configure the cross-validation procedure\n",
    "    cv_outer = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # enumerate splits\n",
    "    outer_results = list()\n",
    "    X = vector_matrix\n",
    "    y = train_target['label']\n",
    "    \n",
    "    for train_ix, test_ix in cv_outer.split(X,y):\n",
    "        \n",
    "        # split data\n",
    "        X_train, X_test = X[train_ix, :], X[test_ix, :]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "    \n",
    "        # specify the nested cross validation\n",
    "        nested_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "        # create the grid search instance\n",
    "        search = GridSearchCV(estimator, parameters, scoring='accuracy', cv=nested_cv, n_jobs=-1, refit=True)\n",
    "        \n",
    "        # execute search\n",
    "        result = search.fit(vector_matrix, train_target['label'])\n",
    "        \n",
    "        # get the best performing model fit on the whole training set\n",
    "        best_model = result.best_estimator_\n",
    "        \n",
    "        # evaluate model on the hold out dataset\n",
    "        predictions = best_model.predict(X_test)\n",
    "        \n",
    "        # evaluate the model\n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "        \n",
    "        # store the result\n",
    "        outer_results.append(acc)\n",
    "        \n",
    "        # report progress\n",
    "        print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "        \n",
    "    # summarize the estimated performance of the model\n",
    "    accuracy_mean = np.mean(outer_results)\n",
    "    \n",
    "    #print the best parameter setting\n",
    "    print(\"Classifier: {}\".format(estimator_name))\n",
    "    print(\"Vectorizer: {}\".format(vector_matrix_name))\n",
    "    print(\"Mean Accuracy: {}\".format(accuracy_mean))\n",
    "    print()\n",
    "    \n",
    "    return accuracy_mean, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41b585e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.857, est=0.538, cfg={'leaf_size': 25, 'n_neighbors': 3}\n",
      ">acc=0.686, est=0.538, cfg={'leaf_size': 25, 'n_neighbors': 3}\n",
      ">acc=0.794, est=0.538, cfg={'leaf_size': 25, 'n_neighbors': 3}\n",
      "Classifier: KNeighborsClassifier\n",
      "Vectorizer: tfidf_vectors\n",
      "Mean Accuracy: 0.7789915966386554\n",
      "\n",
      ">acc=0.429, est=0.298, cfg={'criterion': 'gini', 'max_depth': 2}\n",
      ">acc=1.000, est=0.298, cfg={'criterion': 'gini', 'max_depth': None}\n",
      ">acc=0.382, est=0.298, cfg={'criterion': 'gini', 'max_depth': 2}\n",
      "Classifier: DecisionTreeClassifier\n",
      "Vectorizer: tfidf_vectors\n",
      "Mean Accuracy: 0.603641456582633\n",
      "\n",
      ">acc=1.000, est=0.596, cfg={'var_smoothing': 0.1}\n",
      ">acc=1.000, est=0.596, cfg={'var_smoothing': 0.1}\n",
      ">acc=1.000, est=0.596, cfg={'var_smoothing': 0.1}\n",
      "Classifier: GaussianNB\n",
      "Vectorizer: tfidf_vectors\n",
      "Mean Accuracy: 1.0\n",
      "\n",
      ">acc=1.000, est=0.596, cfg={'C': 10.0, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      ">acc=1.000, est=0.596, cfg={'C': 10.0, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      ">acc=1.000, est=0.596, cfg={'C': 10.0, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Classifier: SVC\n",
      "Vectorizer: tfidf_vectors\n",
      "Mean Accuracy: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=1.000, est=0.625, cfg={'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=1.000, est=0.635, cfg={'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      ">acc=1.000, est=0.615, cfg={'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Classifier: MLPClassifier\n",
      "Vectorizer: tfidf_vectors\n",
      "Mean Accuracy: 1.0\n",
      "\n",
      ">acc=0.857, est=0.423, cfg={'leaf_size': 25, 'n_neighbors': 2}\n",
      ">acc=0.686, est=0.423, cfg={'leaf_size': 25, 'n_neighbors': 2}\n",
      ">acc=0.794, est=0.423, cfg={'leaf_size': 25, 'n_neighbors': 2}\n",
      "Classifier: KNeighborsClassifier\n",
      "Vectorizer: count_vectors\n",
      "Mean Accuracy: 0.7789915966386554\n",
      "\n",
      ">acc=0.400, est=0.337, cfg={'criterion': 'entropy', 'max_depth': 4}\n",
      ">acc=1.000, est=0.365, cfg={'criterion': 'gini', 'max_depth': None}\n",
      ">acc=1.000, est=0.365, cfg={'criterion': 'entropy', 'max_depth': None}\n",
      "Classifier: DecisionTreeClassifier\n",
      "Vectorizer: count_vectors\n",
      "Mean Accuracy: 0.7999999999999999\n",
      "\n",
      ">acc=1.000, est=0.587, cfg={'var_smoothing': 0.0001}\n",
      ">acc=1.000, est=0.587, cfg={'var_smoothing': 0.0001}\n",
      ">acc=1.000, est=0.587, cfg={'var_smoothing': 0.0001}\n",
      "Classifier: GaussianNB\n",
      "Vectorizer: count_vectors\n",
      "Mean Accuracy: 1.0\n",
      "\n",
      ">acc=1.000, est=0.577, cfg={'C': 10.0, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      ">acc=1.000, est=0.577, cfg={'C': 10.0, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      ">acc=1.000, est=0.577, cfg={'C': 10.0, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Classifier: SVC\n",
      "Vectorizer: count_vectors\n",
      "Mean Accuracy: 1.0\n",
      "\n",
      ">acc=1.000, est=0.663, cfg={'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      ">acc=1.000, est=0.644, cfg={'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      ">acc=1.000, est=0.625, cfg={'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "Classifier: MLPClassifier\n",
      "Vectorizer: count_vectors\n",
      "Mean Accuracy: 1.0\n",
      "\n",
      ">acc=0.629, est=0.365, cfg={'leaf_size': 25, 'n_neighbors': 2}\n",
      ">acc=0.771, est=0.365, cfg={'leaf_size': 25, 'n_neighbors': 2}\n",
      ">acc=0.706, est=0.365, cfg={'leaf_size': 25, 'n_neighbors': 2}\n",
      "Classifier: KNeighborsClassifier\n",
      "Vectorizer: w2v_cbow\n",
      "Mean Accuracy: 0.7019607843137255\n",
      "\n",
      ">acc=1.000, est=0.346, cfg={'criterion': 'gini', 'max_depth': None}\n",
      ">acc=1.000, est=0.337, cfg={'criterion': 'entropy', 'max_depth': None}\n",
      ">acc=0.765, est=0.327, cfg={'criterion': 'entropy', 'max_depth': 4}\n",
      "Classifier: DecisionTreeClassifier\n",
      "Vectorizer: w2v_cbow\n",
      "Mean Accuracy: 0.9215686274509803\n",
      "\n",
      ">acc=1.000, est=0.356, cfg={'var_smoothing': 0.1}\n",
      ">acc=0.943, est=0.356, cfg={'var_smoothing': 0.1}\n",
      ">acc=0.912, est=0.356, cfg={'var_smoothing': 0.1}\n",
      "Classifier: GaussianNB\n",
      "Vectorizer: w2v_cbow\n",
      "Mean Accuracy: 0.9515406162464987\n",
      "\n",
      ">acc=1.000, est=0.471, cfg={'C': 0.1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      ">acc=1.000, est=0.471, cfg={'C': 0.1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      ">acc=1.000, est=0.471, cfg={'C': 0.1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Classifier: SVC\n",
      "Vectorizer: w2v_cbow\n",
      "Mean Accuracy: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.914, est=0.462, cfg={'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.914, est=0.452, cfg={'activation': 'relu', 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.882, est=0.452, cfg={'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "Classifier: MLPClassifier\n",
      "Vectorizer: w2v_cbow\n",
      "Mean Accuracy: 0.9036414565826331\n",
      "\n",
      ">acc=0.600, est=0.423, cfg={'leaf_size': 25, 'n_neighbors': 5}\n",
      ">acc=0.743, est=0.423, cfg={'leaf_size': 25, 'n_neighbors': 5}\n",
      ">acc=0.618, est=0.423, cfg={'leaf_size': 25, 'n_neighbors': 5}\n",
      "Classifier: KNeighborsClassifier\n",
      "Vectorizer: w2v_skipg\n",
      "Mean Accuracy: 0.6535014005602241\n",
      "\n",
      ">acc=0.600, est=0.365, cfg={'criterion': 'gini', 'max_depth': 3}\n",
      ">acc=0.771, est=0.346, cfg={'criterion': 'gini', 'max_depth': 3}\n",
      ">acc=0.647, est=0.327, cfg={'criterion': 'gini', 'max_depth': 2}\n",
      "Classifier: DecisionTreeClassifier\n",
      "Vectorizer: w2v_skipg\n",
      "Mean Accuracy: 0.672829131652661\n",
      "\n",
      ">acc=1.000, est=0.423, cfg={'var_smoothing': 0.1}\n",
      ">acc=0.914, est=0.423, cfg={'var_smoothing': 0.1}\n",
      ">acc=0.882, est=0.423, cfg={'var_smoothing': 0.1}\n",
      "Classifier: GaussianNB\n",
      "Vectorizer: w2v_skipg\n",
      "Mean Accuracy: 0.9322128851540615\n",
      "\n",
      ">acc=1.000, est=0.519, cfg={'C': 10.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      ">acc=1.000, est=0.519, cfg={'C': 10.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      ">acc=1.000, est=0.519, cfg={'C': 10.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Classifier: SVC\n",
      "Vectorizer: w2v_skipg\n",
      "Mean Accuracy: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.829, est=0.510, cfg={'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.914, est=0.519, cfg={'activation': 'relu', 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.853, est=0.529, cfg={'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Classifier: MLPClassifier\n",
      "Vectorizer: w2v_skipg\n",
      "Mean Accuracy: 0.8652661064425771\n",
      "\n",
      ">acc=0.686, est=0.365, cfg={'leaf_size': 25, 'n_neighbors': 2}\n",
      ">acc=0.543, est=0.365, cfg={'leaf_size': 25, 'n_neighbors': 2}\n",
      ">acc=0.706, est=0.365, cfg={'leaf_size': 25, 'n_neighbors': 2}\n",
      "Classifier: KNeighborsClassifier\n",
      "Vectorizer: fasttext\n",
      "Mean Accuracy: 0.6448179271708684\n",
      "\n",
      ">acc=0.457, est=0.250, cfg={'criterion': 'entropy', 'max_depth': 2}\n",
      ">acc=0.886, est=0.260, cfg={'criterion': 'gini', 'max_depth': 5}\n",
      ">acc=1.000, est=0.279, cfg={'criterion': 'entropy', 'max_depth': None}\n",
      "Classifier: DecisionTreeClassifier\n",
      "Vectorizer: fasttext\n",
      "Mean Accuracy: 0.7809523809523808\n",
      "\n",
      ">acc=0.829, est=0.375, cfg={'var_smoothing': 0.1}\n",
      ">acc=0.714, est=0.375, cfg={'var_smoothing': 0.1}\n",
      ">acc=0.824, est=0.375, cfg={'var_smoothing': 0.1}\n",
      "Classifier: GaussianNB\n",
      "Vectorizer: fasttext\n",
      "Mean Accuracy: 0.7887955182072829\n",
      "\n",
      ">acc=1.000, est=0.442, cfg={'C': 10.0, 'gamma': 'scale', 'kernel': 'poly'}\n",
      ">acc=1.000, est=0.442, cfg={'C': 10.0, 'gamma': 'scale', 'kernel': 'poly'}\n",
      ">acc=1.000, est=0.442, cfg={'C': 10.0, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Classifier: SVC\n",
      "Vectorizer: fasttext\n",
      "Mean Accuracy: 1.0\n",
      "\n",
      ">acc=0.257, est=0.250, cfg={'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      ">acc=0.257, est=0.337, cfg={'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}\n",
      ">acc=0.265, est=0.269, cfg={'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Classifier: MLPClassifier\n",
      "Vectorizer: fasttext\n",
      "Mean Accuracy: 0.25966386554621845\n",
      "\n",
      ">acc=0.657, est=0.663, cfg={'leaf_size': 25, 'n_neighbors': 7}\n",
      ">acc=0.629, est=0.663, cfg={'leaf_size': 25, 'n_neighbors': 7}\n",
      ">acc=0.765, est=0.663, cfg={'leaf_size': 25, 'n_neighbors': 7}\n",
      "Classifier: KNeighborsClassifier\n",
      "Vectorizer: GloVe\n",
      "Mean Accuracy: 0.6834733893557422\n",
      "\n",
      ">acc=0.829, est=0.394, cfg={'criterion': 'gini', 'max_depth': 4}\n",
      ">acc=0.800, est=0.385, cfg={'criterion': 'gini', 'max_depth': 3}\n",
      ">acc=0.971, est=0.375, cfg={'criterion': 'gini', 'max_depth': 5}\n",
      "Classifier: DecisionTreeClassifier\n",
      "Vectorizer: GloVe\n",
      "Mean Accuracy: 0.8663865546218488\n",
      "\n",
      ">acc=0.886, est=0.712, cfg={'var_smoothing': 0.1}\n",
      ">acc=0.743, est=0.712, cfg={'var_smoothing': 0.1}\n",
      ">acc=0.853, est=0.712, cfg={'var_smoothing': 0.1}\n",
      "Classifier: GaussianNB\n",
      "Vectorizer: GloVe\n",
      "Mean Accuracy: 0.827170868347339\n",
      "\n",
      ">acc=0.943, est=0.702, cfg={'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      ">acc=0.886, est=0.702, cfg={'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      ">acc=0.941, est=0.702, cfg={'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Classifier: SVC\n",
      "Vectorizer: GloVe\n",
      "Mean Accuracy: 0.9232492997198879\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=1.000, est=0.683, cfg={'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.714, est=0.702, cfg={'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      ">acc=0.706, est=0.644, cfg={'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "Classifier: MLPClassifier\n",
      "Vectorizer: GloVe\n",
      "Mean Accuracy: 0.8067226890756304\n",
      "\n",
      "\n",
      "The best performance is reached with the estimator GaussianNB and the vectorizer tfidf_vectors with an accuracy of 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\envs\\Python_DataMining\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tune for the best vectorizer-estimator combination\n",
    "def hyper_tune():\n",
    "    \n",
    "    kNeighbors_parameters = {\n",
    "        'leaf_size': range(25,35),\n",
    "        'n_neighbors': range(2, 9)\n",
    "    }\n",
    "    \n",
    "    decisionTree_parameters = {\n",
    "        'criterion':['gini', 'entropy'], \n",
    "        'max_depth':[ 2, 3, 4, 5, None]\n",
    "    }\n",
    "    \n",
    "    gaussianNB_parameters = {\n",
    "        'var_smoothing': [0.0001,0.001,0.01,0.1]\n",
    "    }\n",
    "    \n",
    "    svc_parameters = {\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'gamma': ['auto', 'scale'],\n",
    "        'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "    }\n",
    "    \n",
    "    mlpClassifier_parameters = {\n",
    "        'learning_rate': ['constant', 'adaptive'],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'solver': ['sgd', 'adam']\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # ------ VECTORIZERS ------\n",
    "    train_tokens = get_train_tokens(train_data)\n",
    "    \n",
    "    #TODO: add the other matrices, when done\n",
    "    # list of fitted vectorizers\n",
    "    vectorizer_values = [\n",
    "        get_tfid_vectors(train_data), get_count_vectors(train_data),\n",
    "        get_w2v_cbow_embeddings(train_tokens), get_w2v_skipg_embeddings(train_tokens),\n",
    "        get_fasttext_embeddings(train_tokens), get_glove_embeddings(train_tokens)]\n",
    "    \n",
    "    #Merge vectorizer names and their fitted matrices into one dict\n",
    "    vectorizers = dict(zip(vectorizer_names, vectorizer_values))\n",
    "    del train_tokens\n",
    "    \n",
    "    # ------ ESTIMATORS ------\n",
    "    #TODO: add more estimators\n",
    "    estimators = {\n",
    "        'KNeighborsClassifier': { 'name': 'KNeighborsClassifier', 'estimator': KNeighborsClassifier(), 'parameters': kNeighbors_parameters },\n",
    "        'DecisionTreeClassifier': { 'name': 'DecisionTreeClassifier', 'estimator': DecisionTreeClassifier(), 'parameters': decisionTree_parameters },\n",
    "        'GaussianNB': { 'name': 'GaussianNB', 'estimator': GaussianNB(), 'parameters': gaussianNB_parameters },\n",
    "        'SVC': { 'name': 'SVC', 'estimator': SVC(), 'parameters': svc_parameters },\n",
    "        'MLPClassifier': { 'name': 'MLPClassifier', 'estimator': MLPClassifier(), 'parameters': mlpClassifier_parameters }\n",
    "    }\n",
    "    \n",
    "    best_score = 0\n",
    "    for vectorizer in vectorizers:\n",
    "        for estimator in estimators:\n",
    "            \n",
    "            score, model = param_search( vectorizers[vectorizer], vectorizer, estimators[estimator] )\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_estimator_name = estimator\n",
    "                best_vectorizer_name = vectorizer\n",
    "                best_model = model\n",
    "\n",
    "    print(\"\\nThe best performance is reached with the estimator \" + best_estimator_name + \" and the vectorizer \" + best_vectorizer_name + \" with an accuracy of \" + str(best_score) )\n",
    "    return best_model, best_vectorizer_name\n",
    "\n",
    "\n",
    "#the best performing model and vectorizer\n",
    "model, vectorizer_name = hyper_tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76fdc085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD4CAYAAAD//dEpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVTUlEQVR4nO3df9BeZX3n8ffHgCgKIzYBYwINOJEuMDZCZNlhdbFqQbYV6PRHmI6wrm2EhZk63T8KtlPZncmM2y26y3TFRmUEV6FYyo/tgmtwujI7A+IDRgi/SpAoD8mQFGYFKxM28bt/3Oext+H5cSV57h/J837N3POc+zrXuc83F0/45Fzn3OekqpAkaS6vGXUBkqQDg4EhSWpiYEiSmhgYkqQmBoYkqckhoy5gUBYvXlwrVqwYdRmSdEB54IEH/qGqlky37qANjBUrVjAxMTHqMiTpgJLkBzOtc0pKktTEwJAkNTEwJElNDAxJUhMDQ5LUxMCQJDUxMCRJTQwMSVITA0OS1OSg/ab3/lhxxf8cdQkjteVT/3q/tnf8HL/94fjtn/0dv9l4hCFJamJgSJKaGBiSpCYGhiSpiYEhSWpiYEiSmhgYkqQmBoYkqYmBIUlqYmBIkpoYGJKkJgaGJKnJwAIjyXVJtifZ1Nf2V0k2dq8tSTZ27SuSvNy37nN925yW5OEkm5NckySDqlmSNLNB3q32S8BfADdMNVTV70wtJ7ka+FFf/6eqatU0n3MtsBa4D7gTOAe4a/7LlSTNZmBHGFV1D/DCdOu6o4TfBm6c7TOSLAWOrKp7q6rohc/581yqJKnBqM5hvBt4rqqe7Gs7Psl3k3wrybu7tmXAZF+fya5tWknWJplIMrFjx475r1qSFrBRBcaF/PzRxTbguKp6J/CHwFeTHAlMd76iZvrQqlpfVauravWSJUvmtWBJWuiG/sS9JIcAvwGcNtVWVTuBnd3yA0meAt5O74hied/my4Gtw6tWkjRlFEcY7wcer6qfTTUlWZJkUbd8ArAS+H5VbQNeSnJGd97jIuD2EdQsSQveIC+rvRG4FzgxyWSSj3ar1vDqk93vAR5K8j3gr4FLqmrqhPmlwBeAzcBTeIWUJI3EwKakqurCGdr/zTRttwC3zNB/AjhlXouTJO01v+ktSWpiYEiSmhgYkqQmBoYkqYmBIUlqYmBIkpoYGJKkJgaGJKmJgSFJamJgSJKaGBiSpCYGhiSpiYEhSWpiYEiSmhgYkqQmBoYkqYmBIUlqYmBIkpoM8pne1yXZnmRTX9tVSZ5NsrF7ndu37sokm5M8keTsvvbTkjzcrbsmSQZVsyRpZoM8wvgScM407Z+pqlXd606AJCcBa4CTu20+m2RR1/9aYC2wsntN95mSpAEbWGBU1T3AC43dzwNuqqqdVfU0sBk4PclS4MiqureqCrgBOH8gBUuSZjWKcxiXJ3mom7I6qmtbBjzT12eya1vWLe/ZPq0ka5NMJJnYsWPHfNctSQvasAPjWuBtwCpgG3B11z7deYmapX1aVbW+qlZX1eolS5bsZ6mSpH5DDYyqeq6qdlfVT4HPA6d3qyaBY/u6Lge2du3Lp2mXJA3ZUAOjOycx5QJg6gqqO4A1SQ5Lcjy9k9v3V9U24KUkZ3RXR10E3D7MmiVJPYcM6oOT3AicBSxOMgl8EjgrySp600pbgI8BVNUjSW4GHgV2AZdV1e7uoy6ld8XV64G7upckacgGFhhVdeE0zV+cpf86YN007RPAKfNYmiRpH/hNb0lSEwNDktTEwJAkNTEwJElNDAxJUhMDQ5LUxMCQJDUxMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU0MDElSEwNDktTEwJAkNTEwJElNDAxJUhMDQ5LUZGCBkeS6JNuTbOpr+89JHk/yUJJbk7ypa1+R5OUkG7vX5/q2OS3Jw0k2J7kmSQZVsyRpZoM8wvgScM4ebRuAU6rqHcDfA1f2rXuqqlZ1r0v62q8F1gIru9eenylJGoKBBUZV3QO8sEfbN6pqV/f2PmD5bJ+RZClwZFXdW1UF3ACcP4ByJUlzGOU5jH8L3NX3/vgk303yrSTv7tqWAZN9fSa7NknSkB0yip0m+WNgF/CVrmkbcFxVPZ/kNOC2JCcD052vqFk+dy296SuOO+64+S1akha4oR9hJLkY+DXgd7tpJqpqZ1U93y0/ADwFvJ3eEUX/tNVyYOtMn11V66tqdVWtXrJkyaD+CJK0IA01MJKcA/wR8KGq+klf+5Iki7rlE+id3P5+VW0DXkpyRnd11EXA7cOsWZLUM7ApqSQ3AmcBi5NMAp+kd1XUYcCG7urY+7orot4D/Mcku4DdwCVVNXXC/FJ6V1y9nt45j/7zHpKkIWkKjCSnVNWmuXv+k6q6cJrmL87Q9xbglhnWTQCn7M2+JUnzr3VK6nNJ7k/y76a+bCdJWliaAqOq/iXwu8CxwESSryb5wEArkySNleaT3lX1JPAn9E5a/yvgmu42H78xqOIkSeOjKTCSvCPJZ4DHgF8Bfr2q/lm3/JkB1idJGhOtV0n9BfB54BNV9fJUY1VtTfInA6lMkjRWWgPjXODlqtoNkOQ1wOuq6idV9eWBVSdJGhut5zDupvc9iCmHd22SpAWiNTBeV1U/nnrTLR8+mJIkSeOoNTD+McmpU2+6GwS+PEt/SdJBpvUcxseBryWZuvHfUuB3BlKRJGksNQVGVX0nyS8BJ9K75fjjVfX/BlqZJGms7M3NB98FrOi2eWcSquqGgVQlSRo7rTcf/DLwNmAjvbvJQu9BRgaGJC0QrUcYq4GTph54JElaeFqvktoEvGWQhUiSxlvrEcZi4NEk9wM7pxqr6kMDqUqSNHZaA+OqQRYhSRp/rZfVfivJLwIrq+ruJIcDiwZbmiRpnLTe3vz3gb8G/rJrWgbcNqCaJEljqPWk92XAmcCL8LOHKR092wZJrkuyPcmmvrY3J9mQ5Mnu51F9665MsjnJE0nO7ms/LcnD3bprkmRv/oCSpPnRGhg7q+qVqTdJDqH3PYzZfAk4Z4+2K4BvVtVK4Jvde5KcBKwBTu62+WySqSmva4G1wMrutednSpKGoDUwvpXkE8Dru2d5fw34H7NtUFX3AC/s0XwecH23fD1wfl/7TVW1s6qeBjYDpydZChxZVfd23wG5oW8bSdIQtQbGFcAO4GHgY8Cd9J7vvbeOqaptAN3PqWmtZcAzff0mu7Zl3fKe7dNKsjbJRJKJHTt27EN5kqSZtF4l9VN6j2j9/IDqmO68RM3SPq2qWg+sB1i9erXfSpekedR6L6mnmeZ/1FV1wl7u77kkS6tqWzfdtL1rnwSO7eu3HNjatS+fpl2SNGStU1Kr6d2t9l3Au4FrgP++D/u7A7i4W74YuL2vfU2Sw5IcT+/k9v3dtNVLSc7oro66qG8bSdIQNQVGVT3f93q2qv4L8CuzbZPkRuBe4MQkk0k+CnwK+ECSJ4EPdO+pqkeAm4FHga8Dl1XV1F1xLwW+QO9E+FPAXXv5Z5QkzYPWKalT+96+ht4RxxGzbVNVF86w6n0z9F8HrJumfQI4paVOSdLgtN5L6uq+5V3AFuC3570aSdLYar1K6r2DLkSSNN5ap6T+cLb1VfXp+SlHkjSu9uaJe++idzUTwK8D9/DzX7aTJB3E9uYBSqdW1UsASa4CvlZVvzeowiRJ46X1exjHAa/0vX8FWDHv1UiSxlbrEcaXgfuT3ErvG98X0LsRoCRpgWi9Smpdkrvofcsb4CNV9d3BlSVJGjetU1IAhwMvVtV/BSa7W3hIkhaI1ke0fhL4I+DKrulQ9u1eUpKkA1TrEcYFwIeAfwSoqq3McWsQSdLBpTUwXumeeFcASd4wuJIkSeOoNTBuTvKXwJuS/D5wN4N7mJIkaQzNeZVU9xyKvwJ+CXgROBH406raMODaJEljZM7AqKpKcltVnQYYEpK0QLVOSd2X5F0DrUSSNNZav+n9XuCSJFvoXSkVegcf7xhUYZKk8TJrYCQ5rqp+CHxwSPVIksbUXFNStwFU1Q+AT1fVD/pf+7LDJCcm2dj3ejHJx5NcleTZvvZz+7a5MsnmJE8kOXtf9itJ2j9zTUmlb/mE+dhhVT0BrAJIsgh4FrgV+Ajwmar6858rIDkJWAOcDLwVuDvJ26tq93zUI0lqM9cRRs2wPF/eBzw1x9HKecBNVbWzqp4GNgOnD6AWSdIs5gqMX+6mjF4C3tEtv5jkpSQvzsP+1wA39r2/PMlDSa5LclTXtoyff7LfZNf2KknWJplIMrFjx455KE+SNGXWwKiqRVV1ZFUdUVWHdMtT74/cnx0neS29+1N9rWu6FngbvemqbcDVU12nK22GetdX1eqqWr1kyZL9KU+StIe9ub35fPsg8GBVPQdQVc9V1e6q+im9245MTTtNAsf2bbcc2DrUSiVJIw2MC+mbjkqytG/dBcCmbvkOYE2Sw7pncKwE7h9alZIkoP2Le/MqyeHAB4CP9TX/WZJV9Kabtkytq6pHktwMPArsAi7zCilJGr6RBEZV/QT4hT3aPjxL/3XAukHXJUma2SinpCRJBxADQ5LUxMCQJDUxMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU0MDElSEwNDktTEwJAkNTEwJElNDAxJUhMDQ5LUxMCQJDUxMCRJTQwMSVITA0OS1GQkgZFkS5KHk2xMMtG1vTnJhiRPdj+P6ut/ZZLNSZ5IcvYoapakhW6URxjvrapVVbW6e38F8M2qWgl8s3tPkpOANcDJwDnAZ5MsGkXBkrSQjdOU1HnA9d3y9cD5fe03VdXOqnoa2AycPvzyJGlhG1VgFPCNJA8kWdu1HVNV2wC6n0d37cuAZ/q2nezaXiXJ2iQTSSZ27NgxoNIlaWE6ZET7PbOqtiY5GtiQ5PFZ+maatpquY1WtB9YDrF69eto+kqR9M5IjjKra2v3cDtxKb4rpuSRLAbqf27vuk8CxfZsvB7YOr1pJEowgMJK8IckRU8vArwKbgDuAi7tuFwO3d8t3AGuSHJbkeGAlcP9wq5YkjWJK6hjg1iRT+/9qVX09yXeAm5N8FPgh8FsAVfVIkpuBR4FdwGVVtXsEdUvSgjb0wKiq7wO/PE3788D7ZthmHbBuwKVJkmYxTpfVSpLGmIEhSWpiYEiSmhgYkqQmBoYkqYmBIUlqYmBIkpoYGJKkJgaGJKmJgSFJamJgSJKaGBiSpCYGhiSpiYEhSWpiYEiSmhgYkqQmBoYkqYmBIUlqMvTASHJskr9L8liSR5L8Qdd+VZJnk2zsXuf2bXNlks1Jnkhy9rBrliSN4JnewC7g31fVg0mOAB5IsqFb95mq+vP+zklOAtYAJwNvBe5O8vaq2j3UqiVpgRv6EUZVbauqB7vll4DHgGWzbHIecFNV7ayqp4HNwOmDr1SS1G+k5zCSrADeCXy7a7o8yUNJrktyVNe2DHimb7NJZg8YSdIAjCwwkrwRuAX4eFW9CFwLvA1YBWwDrp7qOs3mNcNnrk0ykWRix44d81+0JC1gIwmMJIfSC4uvVNXfAFTVc1W1u6p+Cnyef5p2mgSO7dt8ObB1us+tqvVVtbqqVi9ZsmRwfwBJWoBGcZVUgC8Cj1XVp/val/Z1uwDY1C3fAaxJcliS44GVwP3DqleS1DOKq6TOBD4MPJxkY9f2CeDCJKvoTTdtAT4GUFWPJLkZeJTeFVaXeYWUJA3f0AOjqv4P05+XuHOWbdYB6wZWlCRpTn7TW5LUxMCQJDUxMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU0MDElSEwNDktTEwJAkNTEwJElNDAxJUhMDQ5LUxMCQJDUxMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU0OmMBIck6SJ5JsTnLFqOuRpIXmgAiMJIuA/wZ8EDgJuDDJSaOtSpIWlgMiMIDTgc1V9f2qegW4CThvxDVJ0oKSqhp1DXNK8pvAOVX1e937DwP/vKou36PfWmBt9/ZE4IkZPnIx8A8DKnc+WN/+sb79Y33750Cv7xerasl0Kw4ZTD3zLtO0vSrpqmo9sH7OD0smqmr1fBQ2CNa3f6xv/1jf/jmY6ztQpqQmgWP73i8Hto6oFklakA6UwPgOsDLJ8UleC6wB7hhxTZK0oBwQU1JVtSvJ5cD/AhYB11XVI/vxkXNOW42Y9e0f69s/1rd/Dtr6DoiT3pKk0TtQpqQkSSNmYEiSmiyIwEjy5iQbkjzZ/Txqhn5bkjycZGOSiSHUNevtTtJzTbf+oSSnDrqmvazvrCQ/6sZrY5I/HWJt1yXZnmTTDOtHPXZz1Teysev2f2ySv0vyWJJHkvzBNH1GNoaN9Y3y9+91Se5P8r2uvv8wTZ9Rjl9LfXs/flV10L+APwOu6JavAP7TDP22AIuHVNMi4CngBOC1wPeAk/bocy5wF73voZwBfHuIY9ZS31nA347ov+l7gFOBTTOsH9nYNdY3srHr9r8UOLVbPgL4+zH7/Wupb5S/fwHe2C0fCnwbOGOMxq+lvr0evwVxhEHvNiLXd8vXA+ePrpSfabndyXnADdVzH/CmJEvHqL6Rqap7gBdm6TLKsWupb6SqaltVPdgtvwQ8Bizbo9vIxrCxvpHpxuTH3dtDu9eeVxCNcvxa6ttrCyUwjqmqbdD7RQSOnqFfAd9I8kB3m5FBWgY80/d+klf/hWjpMyit+/4X3WHvXUlOHk5pTUY5dq3GYuySrADeSe9fof3GYgxnqQ9GOIZJFiXZCGwHNlTVWI1fQ32wl+N3QHwPo0WSu4G3TLPqj/fiY86sqq1JjgY2JHm8+5fiILTc7qTpligD0rLvB+ndd+bHSc4FbgNWDrqwRqMcuxZjMXZJ3gjcAny8ql7cc/U0mwx1DOeob6RjWFW7gVVJ3gTcmuSUquo/ZzXS8Wuob6/H76A5wqiq91fVKdO8bgeemzoU7H5un+EztnY/twO30puWGZSW252M8pYoc+67ql6cOuytqjuBQ5MsHlJ9cxnr28mMw9glOZTe/4y/UlV/M02XkY7hXPWNwxh2+/6/wP8Gztlj1Vj8Ds5U376M30ETGHO4A7i4W74YuH3PDknekOSIqWXgV4Fpr3CZJy23O7kDuKi72uIM4EdTU2tDMGd9Sd6SJN3y6fR+n54fUn1zGeXYzWnUY9ft+4vAY1X16Rm6jWwMW+ob5RgmWdL9y50krwfeDzy+R7dRjt+c9e3L+B00U1Jz+BRwc5KPAj8EfgsgyVuBL1TVucAx9A7boDcuX62qrw+qoJrhdidJLunWfw64k96VFpuBnwAfGVQ9+1jfbwKXJtkFvAysqe7yi0FLciO9qzwWJ5kEPknvxN7Ix66xvpGNXedM4MPAw908N8AngOP6ahzlGLbUN8oxXApcn97D3V4D3FxVfzsuf38b69vr8fPWIJKkJgtlSkqStJ8MDElSEwNDktTEwJAkNTEwJElNDAxJUhMDQ5LU5P8D7iMl3YnPNZkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555263157894737\n"
     ]
    }
   ],
   "source": [
    "#Apply the model to the test set\n",
    "\n",
    "#fractionize and undersample data\n",
    "test_data, test_target = balanced_fractionize(test_df, 1.0)\n",
    "\n",
    "vector_matrix = get_vectorMatrix(vectorizer_name, test_data)\n",
    "fitted_model = model.fit(vector_matrix, test_target['label'])\n",
    "predictions = fitted_model.predict(vector_matrix)\n",
    "\n",
    "# evaluate the model\n",
    "acc = accuracy_score(test_target, predictions)\n",
    "print(acc)\n",
    "\n",
    "#TODO: apply model on the test data and evaluate it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
